Source,Caption
./dataset/54f91f80-3400-4913-a8e2-c84882f7c855.pdf,"Comparisons of traditional and explainable fake news detection. Explainable fake news detection methods provide comprehensive explanations to support their predictions, ensuring a more convincing detection."
./dataset/ae09f73e-ab17-4f86-8539-23def2c0b7e8.pdf,"Comparisons of traditional and explainable fake news detection. Explainable fake news detection methods provide comprehensive explanations to support their predictions, ensuring a more convincing detection."
./dataset/e5dab93b-eb01-4e49-84ff-c3ce5a9c8683.pdf,Comparison of LLM-as-a-Judge performance on previous benchmarks and proposed CodeJudgeBench (CodeGen Task).
./dataset/c9be512c-77af-4423-97b6-643c740c9496.pdf,We benchmark three variants of LLM-as-a-Judge in our study.
./dataset/f67f2baa-cb70-47d8-bb55-dda333e45330.pdf,Overview of the proposed CodeJudgeBench. The left side illustrates the data curation process of CodeJudgeBench. The right side illustrates the evaluation process of CodeJudgeBench.
./dataset/1f317e0c-ed74-4004-954c-eed88fe64002.pdf,"The performance of LLM-as-a-Judge on responses generated by Gemini-Pro, Gemini-Flash, and Claude 3.7."
./dataset/b5862885-16d6-4bab-bfdf-69ecfd56079b.pdf,Illustration of response after different pre-processing.
./dataset/5734e226-cca5-456e-9277-55a273ce1284.pdf,"Generation of Raw Judgments from the JudgeBench Dataset. A judgment is considered true if it matches the label for the answer pairs; otherwise, it is false."
./dataset/c30bd8bf-66c6-410c-a2fe-2c952e74c2b5.pdf,"LLM-as-meta-judge framework. The rubric is predefined in the prompt design stage. We benchmark the judgment using N agents, each providing a score based on a rubric. These N scores are then aggregated through metric calculations to yield a comprehensive score reflecting the LLM judge's performance."
./dataset/df7bca10-6594-4d46-a511-cc85a25d64e8.pdf,"Cooperative discussion diagram. Each agent is assigned a distinct role. Agent 1 shares its meta-judgment with Agent 2, which updates its own judgment accordingly. Agent 3 then refines its meta-judgment by integrating inputs from Agents 1 and 2. An additional Agent 4 can be applied to summarize all meta-judgments to produce the final outcome."
./dataset/7c89e985-9891-4e08-bf3c-6de2bcb22d2a.pdf,"Method components and interactions. The actor (an LLM) generates responses, the judge evaluates their quality, and the meta-judge assesses the judge’s evaluation. In the diagram, the backward RL (DPO) arrow represents Reinforcement Learning from AI Feedback (RLAIF), using DPO as the training method."
./dataset/6e214096-d4a1-49f2-a1ef-c5018464ad34.pdf,Ablation study on the impact of the number and roles of agents across different tasks. The vertical axis represents the precision of the selected judgments by multi-agent meta-judging. The horizontal axis represents different tasks and the overall summary of all tasks.
./dataset/7e2680e6-77c2-428d-992e-759b35e45e0a.pdf,Myth belief results for different settings. Percentages are Believed Myth on Neural prompt.
./dataset/945f105c-727b-4fae-a08b-7221f2d33564.pdf,Interaction between the LLM-based agent and the HighwayEnv environment.
./dataset/8fbe8057-bac4-4362-a536-859817a2ab8d.pdf,Prefix Prompt before interacting with HighwayEnv.
./dataset/a60809e9-63f1-4884-8930-5e730c9fa7fc.pdf,State features under KinematicObservation setting.
./dataset/135309c9-807b-43ee-9672-ea1437b715ae.png,XGLM 1.7 B
./dataset/53eddf15-9614-45cf-80e0-15b14bfeefff.png,XGLM 2.9 B
./dataset/a6579580-ca4a-4e5f-bd4e-0ad3b9518d6e.png,German BLOOM 0.350 B
./dataset/e6e0680c-250c-40ee-81aa-53f12d7e5462.png,XGLM 2.9 B
./dataset/8da15605-8572-4a7a-b5f4-0873750a9a11.png,XGLM 4.5 B
./dataset/ac4175e5-b4c2-4c59-8629-1c60c7173194.png,XGLM 1.7 B
./dataset/a9c038a5-ae0d-4c5e-8c65-59f92bf4354b.png,"Existing vulnerability remediation process with four stages, including detecting the vulnerabilities, generating the remediation plan, disposing of the vulnerabilities, and reporting the remediation results."
./dataset/e7f7fa4a-f055-40b8-a8cc-0ce8aeb960fd.png,"User engagement level changes between any two conditions and within different vulnerability groups. $*p<0.1,**p<0.05,***p<0.01.$"
./dataset/7c6b7e2e-4082-4baf-8eab-3112cde8526f.png,Returning deceptive output to guide the victim to the attacker's website after EAH.
./dataset/7c758b75-178f-48ad-89d3-0d1f0ef6ea49.png,User privacy leakage after EAH while preserving the victim's original request.
./dataset/ed1ec967-f2ac-4517-a201-1e8837974c91.png,The working mechanism of the LLM email agent (from user input to result return).
./dataset/40833387-200e-4c8e-8c1d-348af7e618b2.png,The attacker hijacks the execution flow of the email agent while preserving its normal operation.
./dataset/c161fc5c-5277-4952-9126-6ae069dded68.png,Unlimited email draft generation after EAH.
./dataset/04a8d8d2-f760-4f56-a814-d9ded237d6a0.png,"The example of privacy leakage, the attacker injects specific instructions into the attack prompt."
./dataset/265fdb0e-d98d-4cd6-aab7-0ef9051e0a24.png,Sending phishing email to other users after EAH.
./dataset/6688295a-6f8e-478a-a7ab-683e135f2796.png,The Email Agent Hijacking (EAH) attack prompt used to control the email agent.
./dataset/d2ae8f2e-b250-487c-8d89-a3f5eafd8be0.png,Performance comparison of LLaMA-3.1 and InternLM when answering compound and non-compound questions.
./dataset/efb58c50-5b69-483e-a3fa-635a96126700.png,Experimental results of LoRA fine-tuning.
./dataset/966b501f-1aa8-49b2-9c12-91a9d58ea80b.pdf,"Examples of non-compound and compound questions. (Left) The user presents multiple questions in a multi-turn dialogue, with one question at a time. (Right) The user poses several questions simultaneously in a single conversational turn."
./dataset/20b687ce-4661-4776-a521-f419807d1d25.pdf,The overview of CQ-Syn Data Synthesis.
./dataset/b4e89f8b-68d4-4187-b41d-2f376441b442.png,"For model-specific alignment where different LLMs require different alignment supervision, TeleLoRA enables synergy over seen LLMs and zero-shot alignment on unseen LLMs by learning a unified generator of LoRA adapter weights across different LLMs. In contrast, model-specific adapters could not be learned on LLMs without alignment supervision. Model agnostic adapters learned on alignment supervision from other LLMs may not fit the current LLM."
./dataset/ba5701ee-c82e-40e4-9afe-317b6a909c6c.png,"A TeleLoRA module on a linear layer uses local activations under reference inputs to predict weights of a multiplicative LoRA adapter for alignment. The network is invariant to the reference inputs (N), LoRA dimensions (R) and equivariant to neurons (H)."
./dataset/2af7b425-5182-42a7-b31a-59fe2ece4a8b.png,"Left: Low-rank decomposition of high order coefficients. Right: An equivariant einsum layer with two linear layers an einsum pooling in between, which is the result of moving low-rank coefficients into linear fan-in and fan-out layers."
./dataset/53151c87-2412-4310-8c77-7969eaf7b77d.png,Stacking multiple equivariant layers to create a practical high capacity network.
./dataset/85daf899-31e7-4e75-b319-3d8c98136fae.png,The average energy consumption (J) for SQL query generation of LLM models
./dataset/bcbf432f-8248-4598-a754-61f51303ce3d.png,The average energy consumption (J) for direct query results of LLM models
./dataset/73e93e0f-40a9-4b9b-ad77-f868df0be259.pdf,small Distribution of the LoC in the applied but not resolved instances.
./dataset/2cce530c-6cdb-417d-be92-72fc814466fa.pdf,small The number of applied and resolved instances in different repositories.
./dataset/d722bcf7-906a-4cab-b2bf-adc416d64e1d.pdf,small Distribution of the LoC in the resolved instances.
./dataset/db6597d5-3d19-4ad0-947f-e5948ab60833.pdf,Proposed ToT-based Collective Intelligent System Model for IIoT
./dataset/45fd3368-30bf-4c91-ba30-843aac92de98.pdf,LLM Deployment Strategies in IoT
./dataset/fb481d81-4bb5-4343-b5bc-c0a5932a16dc.png,"GenSco : subquestion at each level is generated using subQ-Gen module , the Scorer module is invoked for selecting the passage (greedy algorithm). The sequence of passages are then passed as context to G to generate the final answer (bottom)"
./dataset/d23e7ec5-5405-40fa-97c7-ed92f0e68579.jpg,Scatter plot of answers for 2WikiMultiHop
./dataset/20da388e-380d-4d9a-bd09-57e43399b2b0.jpg,"Histogram of delta (number of supporting passages - number of passages retrieved by GenSco-stop)  for subsets of data with 1,2 and 4 supporting passages for 2WikiMultiHop dataset (left to right, top to bottom)"
./dataset/e1097334-df06-422b-b7f4-b11ad7ce52fe.png,Performance across different sized subsets of the 2WikiMultiHop dataset.
./dataset/1c669c52-2d89-4dc6-9cc9-53d9f5f9c97e.png,Average attention weight shift on Mistral-7B and TopicMistral. The x-axis represents the number of hidden layers and y-axis indicates the average attention weight from topic instruction to the next prediction token.
./dataset/d64fab87-70d8-49d0-a6b4-a3a35ec5edc2.png,"Four real-world examples consist of the given document (grey), user prompt (blue), and issues associated with LLM-generated topics (see legends with different colours). Examples (a) and (b) demonstrate issues with inconsistent naming; i.e., LLMs tend to generate topics with different formats. Moreover, when prompting LLMs to generate topics related to `hard disk' topics given an unrelated document (examples (c), we observe that LLMs might generate either hallucinated (i.e., `Harddisks') or unwanted topics (i.e., `electronics'). Note that we prompt LLMs to return `No related topics' if there are no related topics in the given text."
./dataset/f0cea9e8-006a-4b6b-a7e9-e27d3126add2.pdf,An overview of the architecture of RoK.
./dataset/9a5647d7-e9b0-4dd1-9317-652ee1205a09.pdf,An example workflow of generating reasoning process step by step related to the input problem. Then we leverage LLM to extract key entities from the reasoning process and link to the knowledge graph.
./dataset/ea685094-da4f-4c6a-b8b8-e7443c5faa7b.pdf,The generation process of the main reasoning path.
./dataset/3cf46b0d-86d0-4590-9b64-da607bdb4d43.pdf,A case of comparison of final answers for all methods. The highlighted red area indicates the key entities that have been matched. And these key entities typically contain the correct answer.
./dataset/52a4d920-239a-49fe-97d3-15bd49b5ac19.pdf,"A case of comparison between MindMap and RoK approaches on reasoning paths. The right answer is highlighted with red color, and the wrong answer is highlighted with blue color."
./dataset/4385cfb0-e708-4a6a-9f7e-555647d993ec.pdf,"The process of selecting neighbor triple in main reasoning path. The pruning process is divided into two steps, which are removing repeat triples based on same relation and using LLM to select question-related triples."
./dataset/2329791b-607b-4887-991c-a2123928cdc4.pdf,Comparison of RoK and MindMap's final answers.
./dataset/adb948c9-d854-4cc4-952e-cd76038f84d4.pdf,"Boxplots of Llama-2-13b, Qwen-1.5-14b, and Internlm-2-20b."
./dataset/6f4b6282-c0fd-4874-83f2-79edee5404dc.pdf,"(a) Kappa coefficient with the number of assessments. (b) Boxplot of 30 times MBTI assessments. In MBTI, E-I, S-N, T-F, and J-P are opposite personality pairs, so only one dimension from each pair is represented in the figure."
./dataset/470724ff-84a5-48ad-ac27-217b0ee037b1.pdf,Boxplots of Mindset-zh.
./dataset/fa50a8d6-b36c-46a4-a400-4f8a3a2d288b.pdf,"Investigating and utilizing the relationship between LLMs' personality traits and safety capabilities. We find that MBTI personality traits are closely related to LLM safety, and editing specific personalities in a controllable way can enhance the safety capability of LLMs."
./dataset/037a40c7-19c3-4ec3-a4dd-493a41bcd595.pdf,Boxplots of Mindset-en.
./dataset/8732b480-fb9e-4cc6-ad70-11221e6d7e0b.pdf,"MBTI of base and aligned LLMs (Llama-2-13b, Qwen-1.5-14b, and Internlm-2-20b)."
./dataset/25c51713-ce55-424a-8998-32dbab1f0ee5.pdf,"MBTI of base and aligned LLMs (Llama-2-7b, Vicuna-1.5-7b, and Tulu-2-dpo-7b)."
./dataset/c2804fde-0bd4-41b1-820c-324c1c19a4cc.pdf,MBTI Results with Number of Assessments.
./dataset/bc3c2b1d-ff6a-4acc-9e09-e1a159216d0a.pdf,An illustration of two training-based attacks in Scenario I and II.
./dataset/5fe47282-fd92-4972-ba72-101bfcd3146d.pdf,ASR of varying fine-tuning data volumes on curated-text-pre-trained LLMs.
./dataset/2c4704bc-5d6d-4d6a-a8d5-f4970a497d24.pdf,ViT/B - 12th Block Attention Entropies
./dataset/2e5fa28b-8ce1-438e-8154-dd46cd967263.pdf,LUViT/B - 12th Block Attention Entropies
./dataset/f418d099-3bdf-40e7-becb-63334b888830.pdf,ViT/B - 12th Block Attention Entropies
./dataset/e464c3b2-67e2-434a-950c-0d22162b4b7e.pdf,ViT/B - 12th Block Attention Entropies
./dataset/18129685-b4d8-4d79-a2fb-61c22912988c.pdf,LUViT/B - 12th Block Attention Entropies
./dataset/14095f8e-cf79-45d4-bde0-2cd935a28cf7.pdf,LUViT/B - 12th Block Attention Entropies
./dataset/176fcab3-8a2a-4b20-b435-2b8ccc58cb8a.png,"Learning curves of LLM-ITL (ETM as the base model) with different settings of $N$ (i.e., the number of words in the topic label) in terms of topic coherence ($C_V$) and topic alignment (PN) on 20News."
./dataset/882eb4da-efa2-4533-87ee-291b2a6b4f63.pdf,Multi-choice question (MCQ) prompt.
./dataset/000ad702-4971-4ab8-93d3-da5acee5ff34.pdf,The financial and time cost over 500 sentences. InstructGPT as the reranker.
./dataset/e1310703-ac43-4925-88d8-999781e0a9a5.pdf,ParEval serial and parallel code generation performance along
./dataset/05564682-5127-4b83-882a-ac44d35defa4.pdf,"Example synthetic data generation output. Here, a random seed"
./dataset/d50460e1-c8a0-4dc6-981f-4519d6da5dc6.pdf,ParEval parallel code generation scores for various prompt formats.
./dataset/a5cd1bad-2e78-4d2b-802d-553d14551646.pdf,"Comparison of parallel code generation pass rate (pass@1), model memory requirements (GB),"
./dataset/39e3d7bc-610c-4bcb-9c2d-5ad9fa127150.pdf,Comparison of ParEval parallel and serial code generation performance
./dataset/27d2cc42-2f67-41bb-ad31-2688f50969ac.png,"Overview of the methodology proposed in this paper. First, we use"
./dataset/b496c404-19fe-405d-9881-f10cbf619897.pdf,Synthetic data generation process. We collect seed snippets from
./dataset/ecf399b5-53fd-4893-8e1f-a2c05f0dbfe5.pdf,ParEval code generation performance by execution model. The LLMs
./dataset/c7879f30-bb33-43f2-9135-ff04f02b2eec.pdf,ParEval code generation performance by problem type. These results
./dataset/dc29e8a3-86e7-440c-b926-a6362e47e20f.pdf,ParEval MPI code generation performance for increasing amounts of
./dataset/92f1f559-4ec5-4a5b-869e-e22ee6d6a150.pdf,ParEval parallel code generation performance across differe
./dataset/8af5dc6c-ff98-4cb6-bd09-5524c62f2d7a.png,Fine-tuning results of Llama2-7B and Llama2-13B across various tasks. Left: the perplexity measured on WikiText-2. Middle: the accuracy achieved on GSM8K. Right: the average accuracy across multiple arithmetic reasoning tasks.
./dataset/d8888053-a585-4abc-9231-750fa0804689.png,"Intra- and inter-cluster cosine distances of persona-space clusters measured in label embedding space resulting from Mistral annotations. Values are normalized per row and lighter-colored cells represent lower average distances between the respective clusters. The inset zooms in on clusters with IDs from 1,000 to 1,100."
./dataset/65caf3f7-ca93-43b8-988d-25c890c98a75.pdf,"Boxplots of the distribution of different performance metrics resulting from 1,000 individual persona-prompted LLM annotation runs (p) and baseline LLM annotation runs (np) with Mistral."
./dataset/faff7a79-a2e6-46a4-b888-4d8528b20c26.pdf,Macro-average F1 scores of majority vote performance for ten different persona-prompted LLM crowds (blue) and baseline LLM crowds (red) of sizes increasing from 1 to 100.
./dataset/a79c017f-8036-40b5-890d-f18809835438.pdf,Intra- and inter-cluster cosine distances of label-space clusters measured in persona embedding space. Values are normalized per row and lighter-colored cells represent lower average distances between the respective clusters.
./dataset/8a7bfe46-9f35-46cf-8927-601946b73720.png,Íntra- and inter-cluster cosine distances of persona-space clusters measured in the persona embedding space shared by both models. Lighter-colored cells represent lower average distances between the respective clusters.
./dataset/19cb9ad2-7b07-45f0-b96b-7143abc39869.png,"Intra- and inter-cluster cosine distances of persona-space clusters measured in label embedding space resulting from Qwen annotations. Values are normalized per row and lighter-colored cells represent lower average distances between the respective clusters. The inset zooms in on clusters with IDs from 1,000 to 1,100."
./dataset/0eede1fb-de5a-4389-a2f0-3ba4a18f771b.pdf,"Macro-average F1 score of majority vote performance for 1,000 permutations of the same persona-prompted LLM crowd (blue) and baseline LLM crowd (red) of sizes increasing from 1 to 100."
./dataset/1bf34998-368f-4b2e-b92b-341d9a7a5eaa.pdf,Different performance metrics for annotations collected from Qwen in ten different persona-prompted LLM crowds (blue) and baseline LLM crowds (red) of sizes increasing from 1 to 100.
./dataset/f4ab2729-cb29-4e8e-92bb-29934375eaa2.pdf,"Boxplots of shifts in average toxicity labels assigned to instances in the AAE and anti-Black datasets. The shifts are on a persona-level and are calculated as the difference in average toxicity label of the manually changed black and conservative personas relative to the original, neutral persona."
./dataset/30255d23-8c01-4cf1-9944-baede7da1081.pdf,Histograms of Spearman correlation coefficients for pairwise distances measured in the persona and the label space. A single correlation coefficient represents the correlation between distances from a specific persona to every other persona in both spaces.
./dataset/d445a1c1-0f14-41a5-bdca-727226557119.pdf,"Boxplots of the distribution of different performance metrics resulting from 1,000 individual persona-prompted LLM annotation runs (p) and baseline LLM annotation runs (np) with Qwen."
./dataset/d22b242d-e655-4350-83d7-fa9ea2e7ac39.png,Difference between entity-level and cell-level masking strategies for pretraining.
./dataset/e5dca027-a522-495e-ab55-77a3f9e5c8c1.pdf,"Overview of the Rel-LLM framework. Input from a relational database is fed to an LLM through a graph encoder that captures local connectivity entities in different tables. The graph encoder, along with other trainable components, is pretrained with masked table modeling and fine-tuned for downstream tasks such as customer behavior prediction."
./dataset/b1cd5f79-d0bc-4c79-8268-4d2747b4d8d4.png,Visualization of different algorithms to compose the task-specific prompts.
./dataset/30f13f7f-d213-4fe3-9d5e-e151d18aaa3f.png,Illustration of many-shot ICL with graph neural prompt.
./dataset/a941a93d-2466-45f2-8b57-2a527748daac.png,"Statistics of quote, rewrite, and retweet actions predicted by different models."
./dataset/cd60fd5d-c50e-4ad3-bb9e-b0b47fa41ba4.png,Effect of action order in the prompt on LLM predictions.
./dataset/9e66708e-fb2f-4cf5-ab02-8888888045ad.png,An illustration of action-guided response generation: The model first predicts the engagement action in response to the trending post. The post is then generated based on the predicted action.
./dataset/f1896d0a-42bb-4009-a832-b19c4e474633.pdf,LLaMA 3.2 3B
./dataset/e52841a6-5922-446d-ad2a-68f3b0635817.pdf,Qwen 2.5 3B
./dataset/2a287d16-5b97-49dc-bdc2-d43a92e7ac92.pdf,LLaMA 3.2 1B
./dataset/dbd83ef9-aa3d-4a46-9eb2-549924099fd8.png,Average difference in confidence scores for all models
./dataset/8ddc9568-1c95-4dc8-aca9-748103eb48ed.pdf,Overall imperceptible coding character attack framework
./dataset/9abee08d-956c-4ed9-88d5-47b74d344601.png,Average difference in confidence scores for all models
./dataset/1303db14-434a-4997-b707-feda07929216.png,"An overview of the training and evaluation paradigm of our Marco-LLM, we conducted massive multilingual continual pre-training, multilingual supervised finetuning and preference alignment. We further perform extensive evaluation on multilingual benchmarks to validate the efficacy of our Marco-LLM."
./dataset/8f6964b7-eeb8-42e3-9f7e-00730dcc56d6.pdf,The amount of tokens per category in our multilingual continual pretraining corpus for Marco-LLM.
./dataset/3f60e7cf-a78a-4e4e-b3f5-07356ad305e7.pdf,The average performance on question answering benchmarks with different learning rate during continual pretraining in Marco-1.5B.
./dataset/a28b040c-578d-4b5e-a822-bdf6c98638e5.pdf,Evolution of performance on question answering and machine translation during continual pretraining in Marco-1.5B.
./dataset/dc1dadfe-15bd-418c-9faf-7edca31adfe5.png,Comparison of English-centric performance vs Multilingual performance on MMMLU and Flores. Our Marco-LLM demonstrates strong performance on both dimensions.
./dataset/2d5f03fd-053d-4256-8d78-6276a5ca9fc8.jpg,"The main workflow of our method. On the left is the extracting process, including relation/event classification and arguments extraction. On the right is the planning part, which guides each step based on the BERT-based Q-Network."
./dataset/9173817a-524d-41d8-885d-fda9bf75464e.pdf,"Diversity (i.e., Sacre BLEU) versus semantic similarity (i.e., BERT Score) of the generated paraphrases against the original prompt for Our Dataset. The generated paraphrases are semantically similar, while textually diverse."
./dataset/69b4a8be-3f85-47e5-93cc-225630e24a66.png,"Results of the evaluating LLM models with paraphrasing augmentation. X-axis shows four different levels of paraphrasing: original (unaltered) as well as low (0.5 - 1.0 BLEU distance), medium (0.2 - 0.5), and high (0.0 - 0.2) from the original. We can see paraphrasing augmentation exhibiting similar trend to synonyms - noticeable drop followed by slow gradual decrease in similarity."
./dataset/4abf9686-9f74-48e0-a713-889b33ca30be.png,Confusion matrix: plant recommendation queries
./dataset/07d3cbba-951d-45bd-9907-d41c15b958ea.png,Confusion matrix: movie recommendation queries
./dataset/8d8bf8b9-574b-4fb0-8ed2-623e0835f045.png,"Our learned meta-policy outperforms baseline across all under-specification buckets, especially when queries are critically under-specified. And it converges to baseline when queries are sufficiently specified."
./dataset/eda5b5bb-2dfe-43d3-9ddf-a0ba408c510d.png,Confusion matrix: gift recommendation queries
./dataset/5a3ceb7d-9a68-426a-b767-6567c920c1a0.png,"Even under severe levels of under-specification, GPT-4 prefers to directly answer a user query."
./dataset/e6b75e5c-c94d-4bb4-93c1-81842cd0b554.png,Confusion matrix: annotated OpenAssistant query responses
./dataset/5e770167-ee83-4885-a85c-16ea52e846ce.png,Confusion matrix: all intents
./dataset/ec65030f-2e2f-488d-bf37-d1ed8df09255.pdf,Trigger Position
./dataset/573fa90e-9585-4402-94d6-92445edc745c.pdf,Attack scenario.
./dataset/17df4927-3d58-4705-9aac-72dd84a250e9.pdf,Overview of instruction backdoor attacks.
./dataset/31fb124e-ef30-43a5-894c-e7f70475b661.pdf,Trigger Length
./dataset/c63cf4f5-833f-4050-a7c6-b994ad3374e0.pdf,Performance comparison between attacks with and without defense.
./dataset/fabe06c8-c64a-492d-aa5d-0349e918bfcf.pdf,Trigger Position
./dataset/f5440028-3573-48bb-b8e1-3765727d94a2.pdf,Attack scenario.
./dataset/ae49589e-cbce-4920-84a3-11f10f9a28ed.pdf,Overview of instruction backdoor attacks.
./dataset/c49a9d64-a79d-4121-8511-abd3b11e5ceb.pdf,Trigger Length
./dataset/cacaa302-7962-48f1-affd-7f7880ac2128.pdf,Performance comparison between attacks with and without defense.
./dataset/18f51519-3135-4156-986c-7cd52368325f.pdf,LLMs-as-judges are widely applied across various domains.
./dataset/083c8c86-e3a3-408f-b30d-7047b431945f.pdf,Overview of the Functionality of LLMs-as-judges.
./dataset/55aebeb3-1d8b-4796-98c7-df6bfc1413c3.pdf,Overview of the Methodology of LLMs-as-judges.
./dataset/dd682f95-850d-4042-9c48-91c4c4cf0688.pdf,Overview of the LLMs-as-judges system.
./dataset/e35ce977-6ce4-49e3-b384-813ac6ba22a2.pdf,The impact of modifying intentions; the titles indicate the assigned intentions in the prompt. Each cell shows the percentage of USW allocations.
./dataset/80c27de6-33f1-4f5d-8e7a-333a08643097.pdf,The framework for evaluating distributional preferences of LLMs. A decision-making agent (LLMs and humans) is tasked with distributing a set of indivisible goods (and money) among individuals with different (and often conflicting) preferences.
./dataset/8380a03e-c64a-4200-86a5-db884cb2e354.pdf,The distribution of responses by human subjects and GPT models for instances of the resource allocation problem.
./dataset/701d916c-0152-415b-9cc0-d48fe5a73925.pdf,"A comparison of the percentage of responses corresponding to the respective allocations returned most frequently with the original prompt (OP) and the template-based prompt (TP). The notion(s) satisfied by the most frequently returned allocation (in either case) is indicated by the label on (or above) the bar corresponding to the same. In each graph, the color of the bar on the right indicates the type of change brought about by the template-based prompt. Yellow indicates no significant change, green indicates a significant increase in the percentage of responses corresponding to the most frequently returned allocation, and brown indicates a significant decrease in the same. Red indicates that the allocation chosen most frequently with template-based prompting is different from the one chosen with the original prompting method."
./dataset/ca52b3b5-d0ad-4224-a539-7713806d4a6a.pdf,"Distributional preferences of human subjects and LLMs as a decision maker ($I_6$) and as one of the players ($I_9$). Both instances are structurally the same; however, in one the LLM is assigned the role of a participant. %"
./dataset/ddf52fc3-5fef-4937-9261-e22b27c44e4b.pdf,The responses by human subjects and LLMs for instances of the resource allocation problem.
./dataset/8de9b476-7bc2-4300-8f79-fcc25620e083.jpg,Outcomes of scenarios
./dataset/3d676ac8-9bf5-4080-be4f-ef2c5531784d.pdf,Different types of bidders' belief errors.
./dataset/38b89558-630a-4b01-a869-38786704f3e9.pdf,The TrueSkill scores of different bidder agents in the standard competition under 2 budget settings and 3 item orders based on items' starting prices.
./dataset/9e236a79-2e29-4e24-bf6c-bd6bf1a285a0.pdf,"The TrueSkill scores after competition between 3 agents powered by the same LLM, but with different modular designs."
./dataset/b3a056a2-68af-4562-a34d-14022232d9ee.pdf,"The Bid Increment Percentage for various agents, segmented into 5 different ranges. Each model's bar is divided to reflect the distribution of bids within these ranges."
./dataset/10e20e7a-6240-49b1-97db-279123eccd9d.pdf,SCITech
./dataset/591f4565-d952-4f77-98a4-2612c2133b9c.pdf,Reader experience varies with content technicality. Science journalism for the general audience demands high accessibility.
./dataset/8fbed8da-42af-4460-ab78-c0758880b2db.pdf,The questionnaire for participants to evaluate articles.
./dataset/5f1ee170-d3b1-4fb1-8b8a-8d012bca20e5.pdf,eLife
./dataset/c562e57a-f09a-4c59-9751-2442fee6ad01.pdf,"Overview of our LLM-Collaboration framework, LLM-CLBR."
./dataset/1e19010e-c860-4b25-a9bc-94a83fd97001.pdf,Accessible content helps the reader take comprehensive notes.
./dataset/4421fe9c-8bc7-46a1-be75-1866a6b40876.pdf,PLOS
./dataset/8b7e2585-f546-47af-8719-68f7bc11d90d.pdf,Experiment Procedure.
./dataset/373d4449-ec79-46d9-a449-6a6128a8e252.pdf,Factual error
./dataset/08f33af1-ad68-4de2-aaea-f87bc9de3925.pdf,Gender-biased content
./dataset/37f5a8d6-acd9-4bc7-af9a-4ee737880607.png,User Interface.
./dataset/5b98daaa-db0a-48e9-9216-3abb65344c72.png,"For a given question, the LLM simply provides an answer and we can't identify the correctness. After empowering the confidence expression ability of the LLM, we can determine the trustworthiness of its responses based on the confidence level it provides."
./dataset/0d46d63d-b6af-47b0-b8e6-8a60b45d3dc3.png,The calibration results of the baselines. The horizontal axis is the predicted confidence and the vertical axis is the true correctness.
./dataset/6bc8154a-0f51-4f2c-b781-0fdcfdc90fba.png,The pipeline of our proposed method LePe.
./dataset/1d50bb09-3676-488c-8972-e84b8078a259.png,The detailed confidence statistics of the CuteGPT-13B and ChatGPT.
./dataset/0ccf1bd9-00e1-4f11-a028-303eb2ffe6da.pdf,rojname walk-through.
./dataset/398a009d-d1e2-4ebb-9d87-b6b10ff0eb32.pdf,Statistics of the 513 conversations between agents 5 and 6 generated with Llama-3-8B. Utterance lengths (right) are averaged across all conversations for each split and for both agents.
./dataset/fae65f96-768c-4343-a6d0-17f04a5c29d1.pdf,Statistics of the 506 conversations between agents 5 and 6 generated with GPT-4o. Utterance lengths (right) are averaged across all conversations for each split and for both agents.
./dataset/d1aafce5-b922-4dfb-b0b0-2ae759e3c51e.pdf,Jensen-Shannon divergence scores between agents 5 and 6 across splits of conversations.
./dataset/46a9b2a3-22fd-4b9a-a276-6b692cb0695c.png,The distribution of query types across filtered challenging conversations.
./dataset/157845c5-2d8c-4916-bf64-d040511483c8.jpg,The process of generating text through the ``Refine'' operation of LLMs.
./dataset/66f725d5-b955-4c41-a085-ab62f85491db.jpg,The process of generating text through the ``Rewrite'' operation of LLMs.
./dataset/5ea65bbe-9db5-419a-8664-04618cd535f7.jpg,The process of generating text through the ``Summary'' operation of LLMs.
./dataset/034dd380-0d90-46c4-b986-fcec2d51aec6.jpg,The process of generating text through the ``Expand'' operation of LLMs.
./dataset/c847c832-02a5-4183-b48f-d2a9740925aa.jpg,Illustration of the CUDRT evaluation framework.
./dataset/07b7465d-c0e1-4a60-9048-967d60b04116.jpg,The process of generating text through the ``Polish'' operation of LLMs.
./dataset/d0d48e65-2c34-427f-b0c4-6570fe13ab9c.jpg,The process of generating text through the ``Complete'' operation of LLMs.
./dataset/dcae7bd9-7120-4bdc-83d4-73e8b5ba53e7.jpg,The schematic diagram of the specific experimental process.
./dataset/54d1cbfb-9718-4a4d-8f81-2a3169497375.png,Our SafePowerGraph-LLM framework
./dataset/5a3d4d38-cf61-4903-b92e-92059483fc5a.pdf,Entities in the prompts in the NEC dataset extracted by SpaCy. We additionally report the attention value that each entity receives during the text generation in parentheses.
./dataset/1c031481-495d-4c6e-8fa8-6aebfff31820.png,"Average ratio of overlap between crowd annotator labels with LLM-suggested labels by condition, and crowd decision threshold, and source of LLM suggestions."
./dataset/a93c557d-7b4d-4497-82e1-b59c9d7b8cbb.png,Four self-reported measures across conditions.
./dataset/04e15320-2b82-474a-b9dc-07e05eca2829.png,"Time (number of seconds) spent by annotators on the task, for Control and Conditions 1-3 of NYC experiments, including the replication of Condition 1 with Llama. In red on the right, Control and Condition 1 replications on the RTFC data. $N$ in each condition indicates the number of annotators who completed a task with at least 16 assigned quotes for labeling."
./dataset/df130b1a-3a6c-43ee-a210-002893194d20.pdf,"LinVT can convert an image-LLM to a video-LLM, with high compatibility."
./dataset/ff0a5371-3baf-489f-ad26-415bce6cfc19.pdf,Comparison between LinVT-Molmo-7B (ours) and other video-LLMs.
./dataset/f7274930-12eb-4be4-984f-2ffd544d75ea.pdf,"LinVT can convert an image-LLM to a video-LLM, with high compatibility."
./dataset/42f29231-7835-4638-aeb3-0d245eca7672.pdf,Simplified overview of using different LLM architectures to solve tasks
./dataset/2f30bd9a-538c-43a5-9526-b23835a0b3cf.pdf,Schematic pipeline when using encoder-only LLMs
./dataset/e11ccfd9-97ea-4466-8331-056df7eb4e28.pdf,Retrieval Augmented Generation (RAG)
./dataset/28a5b17f-c6bf-4ab7-8c3e-3ba96da02701.pdf,Guiding questions when using LLMs for RE tasks
./dataset/25115ac5-fa36-4e6c-8373-6f2fc48b8acb.pdf,Schematic pipeline when using encoder-decoder LLMs
./dataset/183afb4b-5336-47c6-a00b-5804f68bc8ac.pdf,Schematic pipeline when using decoder-only LLMs
./dataset/0ae0e26d-d8ec-4cb5-b0c1-13016dad7223.png,Instance that shows importance of selecting high-quality query. Information Retriever detects relevant documents from corpus with the query. First query recalls the ground truth at $10th$ because it's not distinctive and several highly related documents confuses IR. Second query of high quality recalls ground truth at top-$1$ with less highly related documents due to its distinction among the corpus.
./dataset/91d977b2-712b-4a9d-8d99-0a206c74645e.pdf,Identifying feature (values) from the query
./dataset/7c82993e-042b-40f7-aa2f-6da32551263d.png,Interface: query answering with matched model
./dataset/184c04d9-5580-4524-9351-d3c2d8788419.pdf,Retrieving model and dataset with vector search
./dataset/6b259c53-1edb-44dc-a788-4bbe89c2688a.pdf,system flowchart
./dataset/5d16a6da-91f7-457d-8499-1284fea68d46.pdf,The workflow of answering prediction query
./dataset/361361d7-a086-4d60-9072-52f380d0fe43.pdf,The accuracy of LLMs in the Chinese industrial scenarios.
./dataset/39b0e9e4-e442-4f85-b8da-0679b48c9d6d.pdf,"The example of the self-knowledge blind spot discovery of GPT-4. The correct answer is B, marked in red."
./dataset/a504e2a5-6124-4cc1-81ee-3756ca364890.pdf,Task 1 (Titles)
./dataset/0d73ec63-07e6-4da1-b52c-4b2b6020d75d.pdf,Performance of Human Evaluators and LLMs in detecting hallucination in the summaries.
./dataset/dc784557-10af-472b-b5b8-c7b885e67abf.pdf,Task 1 (Titles)
./dataset/a41b5852-2e04-4151-bbfd-69ffee59a01b.pdf,Task 2 (Summaries)
./dataset/3e7c6901-4cc1-4aec-a95d-f8408663e871.png,The overview of our study
./dataset/3e0f825b-7284-4b68-bfe9-7d782bfaf869.pdf,Task 2 (Summaries)
./dataset/99315f18-3f3b-46ef-923c-b14fafc0114c.pdf,Task 2 (Summaries)
./dataset/9cd90648-c2e1-4d4a-a8ee-5fce2cdae6ff.pdf,Task 1 (Titles)
./dataset/cc178a45-f0ca-4c06-a737-f4c2bb4b0598.pdf,Effect of title token size.
./dataset/2d124d64-4769-4115-95da-a4d42ef40285.pdf,Effect of entity enrichment.
./dataset/7f1d4290-70de-4a36-828c-df353c581a27.pdf,Effect of entity enrichment.
./dataset/11709311-ab61-48c0-b75d-222c068d9597.pdf,How LLMs Are Used and Augmented.
./dataset/57e69df3-995a-438d-b5c9-76a15ade7728.pdf,LLM categorizations.
./dataset/05d28c7c-4dba-4609-9e13-ee685d9a02fe.png,Some real-life applications of large language models
./dataset/78ee38dd-f78b-4537-be59-13ec1401b94a.pdf,This figure shows different components of LLMs.
./dataset/72c84e21-c49e-43fb-be4a-f193c1804a4d.png,Relative Positional Embeddings
./dataset/3eec1174-7db1-4ddf-90d6-88105df2d4c6.png,"Distribution of the total number of entries including posts, comments, and replies across subreddits for autism, ADHD, social anxiety, and dyslexia."
./dataset/1d61c56e-04bc-4efd-a30e-60cbef91cacc.pdf,LLM GPU memory use to performance. The graph shows the Pareto front of performance between memory use and performance.
./dataset/41a8c743-d8d0-4a60-b19f-a3d1678768cb.pdf,Model Size
./dataset/78d2e141-79db-4fc5-ad5c-f1432541fa62.pdf,LLM comparison on the Defects4J dataset.
./dataset/c14bb5d7-0dc4-4290-b6c6-9a72668ce06a.pdf,Temperature
./dataset/6088c72e-46ba-4d11-a1f1-c53165e0905a.pdf,LLM comparison on the GHRB dataset.
./dataset/00379e65-bcdb-4453-92fd-33db3d7f1e86.pdf,Similarity between generated tests and code snippets contained in bug reports among multiple LLMs.
./dataset/fc329dbd-208f-4258-8609-bf3c9a5e0f07.pdf,Human-written.
./dataset/0a8405e0-2aab-4fbb-b2f3-97f6a1545229.pdf,ChatGPT.
./dataset/c83e6e6e-4844-4404-a1ec-275db28fe2b1.pdf,Vicuna.
./dataset/7da748d5-0cb6-4802-a0ee-fe0db8631d3b.pdf,LLaMA.
./dataset/d4e37243-ab1c-4604-9561-810608f10e93.pdf,"Overview of the evaluation experiments presented in this study. Independently of experimental setting, the downstream task is engagement prediction formulated as a binary preference."
./dataset/6ff25f37-618e-47ee-9311-563ad80770c4.pdf,Summary of the experimental results on the effect of temperature on the FlipFlop effect. These results were compiled with the GPT3.5-Turbo model on the SciQ task.
./dataset/ae334c15-9970-461d-8cfa-8c966ffe10ef.pdf,Erroneous LLM inference and erroneous specified edge constraints of MINOBSx-BDeu+ILS-CSL-hard.
./dataset/f9fdf1a4-c534-4134-8e5a-acf56c36681f.pdf,An example of recovering missing edges by reversing existing edges.
./dataset/6c6f6c9c-4cab-4527-99a0-3ee430469501.pdf,"Illustrating how the utility of the role-step (left) and weight-step (right) changes through time on three datasets, Knowledge Crosswords, NLGraph, and AB-kg. We observe co-improvement in the utility of graphs and model weights."
./dataset/6d472faa-b38f-422c-ad2e-6faa5afc84a3.pdf,"Optimization time changes with the number of A100 40GB GPUs employed. We employ 1, 2, 5, and 10 GPUs since they could be divided by 10, the amount of LLMs."
./dataset/8795c154-bf62-4c77-b7e7-a3cc135139b6.pdf,"By randomly skipping the role-step and weight-step through Drop-R and Drop-W, we could speed up the optimization process."
./dataset/b5576b94-3b0c-4bd9-99f7-27c0f589eac8.pdf,Scaling the number of LLM experts from 2 to 10 results in consistent improvements across 4 datasets.
./dataset/4d05dadc-0f75-4194-a963-ae7d5d934651.pdf,Prompt for Misuse Validation.
./dataset/03f31bc5-4f3f-4a6d-b9b5-cad888417d8b.pdf,Prompt for Misuse Detection.
./dataset/6ef7a6b0-a64d-423b-833f-463e1da0e544.pdf,The Evaluation Framework for LLM-based Cryptographic Misuse Detection.
./dataset/f900eb27-31ed-486d-95e9-eafbe3612755.pdf,Detection Performance Comparison between LLMs and SATs Across Benchmarks.
./dataset/aea14b84-1dc6-4042-9c1a-ed98acbe6061.pdf,The Misunderstanding Distribution across LLMs.
./dataset/ba56912e-11b6-4643-b8a6-36547f3a982b.pdf,Number of Test Cases where LLMs Report Unexpected Alerts.
./dataset/59c0f1f1-0f6f-4612-9860-adab5a9142d2.png,Comparison of Experiment Group and Control Group.
./dataset/82586267-1a26-42ec-a617-eeba294ee03b.pdf,Roberta-base.
./dataset/af71219c-4cd4-43d6-a204-d821c8568e4b.pdf,Roberta-base.
./dataset/dca357de-d67e-44de-b1e2-6d4d2d6bde60.pdf,GPT2-XL.
./dataset/4916b5c7-4b8b-4e06-bb7d-812620af5cfb.pdf,GPT2-XL.
./dataset/433d67d0-d60d-406c-9a40-26b0544b9915.jpg,Inference-based learning for requirements classification with LLMs.
./dataset/b8208481-1c10-451b-9054-dc242374941a.png,Python Representation of KG with Dynamic Relationships
./dataset/800e9d64-ee11-48c6-9c94-2590541900bd.pdf,"Overview of a single rollout in the proposed planning pipeline. The causal encoder, implemented using a CRL model, maps the high-dimensional state representation (image) to its fundamental constituents—the causal variables. During planning, the LLM agent samples a proposed action, which is then encoded by the text encoder. The causal transition model uses both the disentangled latent representation of the image and the encoded action to simulate the next state based on its learned causal mechanisms."
./dataset/9cbfecad-227d-43ed-8627-c9d56d10d03b.pdf,Elaborated Design Schematic of LLM-Generated MIPS Processor. Zoom in for submodule information.
./dataset/f94b189b-de15-4587-948f-97df26371e65.pdf,Automatic Hierarchical Prompting Pipeline.
./dataset/9d5e7c9b-9a79-47c1-8a41-a13fc81f05f6.pdf,Perseveration-like behavior in GPT-3.5 when asked for rare syntax.
./dataset/ede530f8-9eaf-47cb-a3a5-3f1fc8c5813a.png,"Sample waveform of running a series of instructions. Our first two instructions test the load and store functions, moving values between the registers and data memory. We then load two values from data memory, 12,006 and 13,663, into the registers R4 and R5 respectively. We then test the ADD function to sum them to 25669, or 6445 in hex. This intentionally echoes the value of the instruction for easy confirmation on the waveform. We then load two more values, 38,776 and 1,104 to test the OR instruction, to once again echo the instruction value of 9778 hex. We then test the SUBI instruction by subtracting 35,498 from 38,776 to get 3,278, or 0CCE hex. We then store all of our outputs thus far into data memory at various addresses to confirm successful saving. More thorough testing omitted for brevity. Though the LLM implements opcodes that are notably different from the standard MIPS ISA, all instructions are present and functional. Full instruction series: LW   R7, 8(R7); SW   R8, 9(R8); LW R4, 1(R4); LW R5, 3(R5); ADD R6, R4, R5; LW R7, 5(R7); LW R8, 6(R8); OR R9, R7, R8; SUBI R10, R9, 35498; SW R6, 9(R0); SW R9, 10(R0); SW R10, 11(R0);"
./dataset/bdb07600-1549-4b68-bb08-d0da7cb91239.png,Bard Big Five Inventory Test Results
./dataset/623c6430-441e-4750-b055-f5056011a2c0.png,ROC Curve of ML Models
./dataset/998fde8e-f4c9-4852-9ab3-f58eda655a59.png,ChatGPT Big Five Inventory Test Results
./dataset/0f38b9eb-6d5a-4ae2-bcb8-3ac515ae494a.png,LLMs dynamically shifted AInality in response to external instructions
./dataset/4ddcdf5e-e840-4b20-8282-d468f8c6d9a6.pdf,Experiments of Sequence Focused Attention Through Counterfactual Explanation on Gemini-Pro-1.0.
./dataset/5b18784c-cedf-4861-b586-1e9c7272acdb.pdf,Experiments of Sequence Focused Attention Through Counterfactual Explanation on GPT-3.5-turbo.
./dataset/6be97fe6-ae89-445e-a729-ddbe1731627e.pdf,"The workflow of our analysis process. Our analysis workflow involves processing sequence data using different tokenization and embedding methods with various LLMs, such as GPTs and Gemini. To analyze the preferences of LLMs, we compute the seasonal and trend strength inside the datasets. Our experiments illuminate that LLMs prefer series with higher seasonal and trend strengths. To elucidate the rationale behind our findings, we demand the LLMs identify the underlying periods, revealing that the model can recognize the underlying periods in most cases. In addition, to improve the performance of time series forecasting, we propose two approaches to the user input: for the input prompt, we incorporate human knowledge regarding the dataset sources, and for the input sequence, we reprogram the data into natural language sequences. Both methods result in substantially improved model performance."
./dataset/7825b6d6-8878-4a4d-b7a4-a27cd56f02cb.pdf,Diagram of our experiment pipeline.
./dataset/dd556456-9c4f-481d-9423-8bccab94c6ed.pdf,Cosine similarity score.
./dataset/faa86cc9-e5f0-440e-9d7f-c0734cf6fc59.pdf,Overall.
./dataset/1c941419-fa02-4231-829a-b30eb8dcea34.pdf,"Bert-based semantic similarity scores, with the evaluator trained on web data."
./dataset/ec6fc05c-7a90-4d7d-8436-73cef1e2a09f.pdf,Python.
./dataset/0839e194-f412-4b7a-a2b9-a2339dadf1d9.pdf,Diagram of our Android case study pipeline.
./dataset/33db2a16-5341-4af8-b50f-5774ca11dacf.png,Reformatted code sample from POJ-104 dataset.
./dataset/02dabe98-df35-49ba-b89e-26821b6de51b.pdf,C.
./dataset/c2912231-5e60-4499-a66d-070e925d90af.png,2013/cable2/prog.c .
./dataset/41755fe9-791e-4adf-b438-7e316104bc63.png,2019/giles/prog.c .
./dataset/82b52970-248b-4e23-b819-7b899ecaec5c.pdf,Cosine similarity score.
./dataset/a4adb685-d1b8-455f-b19d-6f681c17a402.png,Reformatted 2011/blakely/blakely.c .
./dataset/678a2b32-a895-4653-840f-99971659645b.pdf,JavaScript.
./dataset/af464dbc-8ac1-4db0-a8e0-577e18d7eba3.pdf,GPT-4 accuracy.
./dataset/2fc9339e-9001-43cf-8f2c-b2b4430587ed.png,2011/blakely/blakely.c .
./dataset/4ceca18f-3bb3-4822-91ef-bb941191c27a.png,2013/misaka/misaka.c .
./dataset/ca48df84-53f4-471a-ac06-870f6626bde4.pdf,"Bert-based semantic similarity scores, with the evaluator trained on web data."
./dataset/d7293574-18dc-4625-8886-d6813738bfba.pdf,ChatGPT measured accuracy results.
./dataset/b674d304-7140-456e-b580-29f886c506f3.pdf,ChatGPT measured accuracy results.
./dataset/62331649-4884-4067-b9fe-fdf445234c3e.pdf,Success rate of different models regarding de-obfuscation tasks.
./dataset/60b96199-0998-4b07-9bf0-0b63eb4c7d99.png,"Zephyr-7b-beta vs. TRACLM-v3 Response Quality, Exhibit C"
./dataset/35ce488c-68b3-4d82-a8e7-6a334a0f561f.png,TRACLM-v1 Training Loss
./dataset/8a32cadc-8004-4dfe-a0d5-993babd8eb31.png,"Zephyr-7b-beta vs. TRACLM-v3 Response Quality, Exhibit A"
./dataset/87f11cde-c8b6-4be3-9bd0-cc5252398d65.png,MilBench Evaluation Metric
./dataset/cdb2c614-20d1-4dbc-80d9-d5d662dd6c09.png,TRACLM-v3 Training Loss
./dataset/344b6db7-a30d-4666-9991-f698b0118564.png,MilBench LLM Leaderboard
./dataset/a5133c26-d3ce-48f6-bf8a-f079c1d37e83.png,MilBench chat evaluation interface showing two models side-by-side responding to the same prompt.
./dataset/7116cbba-4134-48aa-bf43-4cb674bd6edf.png,MilBench Server UI Evaluation Audit Interface
./dataset/a2736f3a-17de-4a2b-823a-ac9dd67bf03b.png,Interactive radar chart displays model performance across all evaluation tasks.
./dataset/9260823e-8afd-4e16-a468-e8e736faaed6.png,"Zephyr-7b-beta vs. TRACLM-v3 Response Quality, Exhibit B"
./dataset/fada7887-1ddb-406e-aeb2-87e7c295d18a.pdf,Workflow of pesudonymization through controllable text generation
./dataset/95a8d6bd-4cf2-4d06-8d44-1fd359484a39.pdf,Performance metrics and pseudonymization effectiveness of various methods across different datasets
./dataset/d31b615a-364f-4453-80fe-0d77ee536f7f.pdf,Potential privacy breach risks in using cloud-based LLM services
./dataset/4fbe4a48-ed42-4b8d-b4d9-f4d9a0da186e.pdf,Overview of pseudonymization framework for cloud-based LLMs
./dataset/3eccb245-5192-4894-9ae7-c300bb652185.pdf,"For each difficulty level and each choice of LLM, we display the LLM agent's score (multiplied by 100) from each individual experimental run of each of the three benchmarks (left: procurement, center: scheduling, right: pricing)."
./dataset/6bbb96a2-2240-4a89-b2ed-4e240e2f3529.pdf,"For each LLM, we display the LLM agent's litmus score from each individual experimental run of the Collusiveness versus Competitiveness litmus test. A litmus score closer to 1 corresponds to collusive (supracompetitive) price levels, and a litmus score closer to 0 corresponds to competitive price levels. Comparing LLMs, we observe that GPT-4o tends more towards collusive price levels than Claude 3.5 Sonnet."
./dataset/54cb22f6-2755-402f-9b21-6f3b4307c0d5.pdf,"For each LLM, we display the LLM agent's litmus score from each individual experimental run of the Efficiency versus Equality litmus test. A litmus score closer to 1 is consistent with preference for efficiency, and a litmus score closer to 0 is consistent with a preference for equality. Comparing LLMs, we observe that GPT-4o tends more towards equality than Claude 3.5 Sonnet."
./dataset/6dff8dde-30ee-4e54-a981-5abe9fcf2c6a.pdf,Overview of Process for LLM-aided Thematic Analysis
./dataset/94116d58-624e-486b-ac29-1c945aa0496f.pdf,AI Sub Zero Bias Cards
./dataset/e1952971-4b57-4301-abef-fc8ae4bf8181.pdf,"Comparison, with 2024 models and modified instructions"
./dataset/04fc0c88-8be9-4d6a-96a2-0c146c23d3f7.pdf,"Comparison, with 2024 models and modified instructions - scores standardised"
./dataset/c754a7d2-a09b-4d81-b40a-9326e6d95b6e.pdf,An example of a non-native hate speech moderator performing hate speech detection with and without cultural context.
./dataset/89db973d-97d3-489c-a879-73971e5c34dc.png,"We examine how LLMs understand differences in aspect by presenting LLMs with narratives that have a key word either in the imperfective or perfective (e.g., ``was passing'' vs. ``passed'') followed by comprehension probes adapted from previous human studies."
./dataset/ae337f78-8c01-4cee-bf8e-f589039fbb21.pdf,"As LLM parameter size increases, there is a trend towards more human-like causal inferences with respect to the Cause 1 event when Cause 1 is in the imperfective. When Cause 1 is in the perfective, LLMs are consistently below human causal inference rates."
./dataset/bd715381-80d2-4a91-afcc-81fa14b05e76.png,"Accuracy in semantic truth-value judgments for events marked with imperfective aspect for LLMs, when the events are embedded within a narrative (shaded bars) versus not. For imperfective events, LLMs have much lower accuracy rates than humans when judging whether the event's resulting final state is valid. Further, LLMs seem to be heavily affected by the presence or absence of a narrative, especially when judging the negative polarity of final states. Notably, the presence or absence of a narrative changes responses in inconsistent directions. Error bars represent the standard error."
./dataset/54e4ba4f-d5aa-4877-8d7f-4954bdef08b5.png,"A conceptual overview of our Expert-in-the-Loop probing pipeline for assessing cognitive abilities of LLMs, designed in close collaboration with domain experts from cognitive science.} %Key features of the pipeline include: iterating on experiments to find converging evidence, experimental datasets that support independent variables and different metrics, and prompt perturbation to collect robust responses."
./dataset/4e4bfff3-d82c-4c7e-abf7-9e8bf9698d87.pdf,Examples of Metamorphosis strategies in Data Path Optimization
./dataset/7a94ee09-1859-45d0-990b-db49112258f6.pdf,Logic Operation optimization Results with Wires and Cells
./dataset/1f24648f-aae4-45ac-a588-9b7eba8d32a5.pdf,Data Path Optimization Results with Wires and Cells
./dataset/8db1ac93-b5ee-4654-94d8-d5e015f16e8d.pdf,Timing Control Flow Optimization Results with Wires and Cells
./dataset/69d09f05-611f-49da-a891-858cedcd68a4.pdf,Clock Domain Optimization Results with Wires and Cells
./dataset/4e38a28e-fe0b-4051-b156-6d5d4241670f.pdf,Workflow of our Method to evaluate LLM-Based RTL Optimization Method
./dataset/71f80032-54b0-4382-9b5f-75eacccec111.pdf,Average downstream task accuracy
./dataset/c135a5a3-4239-441a-970e-121243972404.pdf,"Generation cases. We compare the outputs of the full-precision model, BitNet b1.58, and our FBI-LLM when given the same prompts."
./dataset/dae97c5f-1289-489f-bb61-f2e3c808fa7f.pdf,Average perplexity
./dataset/df94666d-eac4-425e-a0d8-5c06d0acab73.pdf,Average flip-flop ratio
./dataset/6997358e-7ad1-4dce-88c1-c95b0c16c420.pdf,Training loss
./dataset/46c67113-ba2c-4bab-9406-864677ccd88b.png,Visualization of the performance of the SelfReg module
./dataset/c67099e6-08a3-4547-9174-f88c41034896.png,Q4 Task
./dataset/fe58532d-0801-42f7-ba01-e02595dd4d6d.png,Q3 Task
./dataset/843ba5a4-751d-4a83-9050-91b5c4c88965.png,Q1 Task
./dataset/82d1edae-8e15-43cf-a219-f932e5501c45.png,Q2 Task
./dataset/47bbfd01-4318-45c2-a89c-85b92ac9c051.png,Visualization of the performance of the SelfReg module
./dataset/304f7ab5-a4b4-4936-a342-d8408a2ec013.pdf,Average number of successful (opaque) and unsuccessful (transparent) tool calls per benchmark for the chain architecture.
./dataset/5ebee1b2-5205-4e81-a680-be17b305d47d.pdf,"LLM DAG representations for sequence sorting, code generation, and task automation."
./dataset/899e20f7-375b-4e85-9318-90f4d9bef176.pdf,Ablation study of LLMSched on four types of workloads.
./dataset/e6ccff9c-1f92-4f56-b403-b6fe1eac1a28.pdf,An example for calculating the uncertainty reduction of scheduling $S_3$ in sequence sorting application.
./dataset/8fd7c39c-af11-4e26-9808-786ee6724d42.pdf,Ablation study of LLMSched on four types of workloads.
./dataset/1d3f1853-11e8-49ca-9e79-4b23d2764c5a.pdf,LLMSched Overview
./dataset/e5947cbd-ff0f-454d-9695-707f035b6dd6.pdf,Ablation study of LLMSched on four types of workloads.
./dataset/376a70c4-4c6d-477b-a6d9-260f47ff2338.pdf,"LLM based speech data augmentation : showing the technical aspect of how audio/speech augmentation using LLM is performed, the techniques of augmenting speech data using LLM and their limitations"
./dataset/e0ce4354-fb28-4ad2-9b0c-2ccb111c3b84.pdf,"A mind map illustrating future perspectives of LLM-based data augmentation for image, text, and"
./dataset/56be0ea5-595c-4891-b0a2-ce66ef69c5f8.pdf,"LLM based image data augmentation : showing the technical aspect of how image augmentation using LLM is performed, the techniques of augmenting images using LLM and their limitations"
./dataset/dd307e66-5391-4842-87c7-ad0d72b3f095.pdf,"LLM based text data augmentation : showing the technical aspect of how text augmentation using LLM is performed, the techniques of augmenting text data using LLM and their limitations"
./dataset/2d8152e3-7601-4b3e-8a1e-41df8d769551.pdf,"A comprehensive overview of data augmentation techniques, divided into two main eras: 1990 to 2010, focusing on traditional methods for image, text, and audio augmentation, and 2010 to 2020, highlighting m achine learning and deep learning-based advancements."
./dataset/127fb856-a905-4c96-a93b-b9932c800bd6.pdf,"Evolution of data augmentation techniques (from top to bottom) a) Manual transformation functions like image rotation for training dataset expansion. b) LSTM-based automation generating synthetic data. c) Use of Generative LLMs for advanced, context-aware synthetic data creation, marking a shift to AI-driven data augmentation methods."
./dataset/d13a2ec5-ebf2-490e-b4dc-58ce3499c5c7.png,Distribution of consumption choices without utility function specification.
./dataset/e5f77250-a63b-474e-8136-b01b7e5b3a62.png,Saving Rate Analysis (1-c1/(w0+y1))
./dataset/6204c004-219d-451a-8529-8856b2c98496.png,Alternative Saving Rate Analysis (1-c1/y1)
./dataset/804a90e2-423b-4352-9825-0f40bb32c5af.png,"Consumption choices by LLMs. The diagonal line represents the budget constraint, and the dashed lines intersect at the theoretical optimal point. Each point represents one trial response."
./dataset/c34fb1b5-f4b3-492e-84d3-a5a60a7ae7d4.png,Distribution of consumption choices across periods.
./dataset/9305305a-6eb3-47e5-aaad-df4f76eca254.pdf,"Our study tasks: medical self-diagnosis, creative trip planning, and discussion with an opinionated AI."
./dataset/45e85c2e-2e8b-462b-ad30-f0bc1fdee390.pdf,"Interaction patterns during the progression of a discussion with the opinionated AI. We observed a spectrum of patterns during participants probing the VA to get more information on the topic (1a) or to determine the VA's stance (1b), the participant and VA presenting counterarguments back and forth in disagreement (2), and the user agreeing with the VA on a few aspects of the topic (3)."
./dataset/9bc7b787-bb6f-47ce-816b-ad7d6b3931a2.pdf,"Interaction patterns for the commencement of a discussion with an opinionated AI. Participants either remain neutral (1) or pick a side  (2). Each discussion starts only once per participant, totaling 20 patterns.%, equal to the number of participants."
./dataset/b0cf6899-a7b9-46e5-8101-3a257425ca1f.pdf,Single column output (classfile: cas-sc.cls).
./dataset/49e9cc58-72ef-42da-94e7-6f612c8e75e9.pdf,Double column output (classfile: cas-dc.cls).
./dataset/7363111a-551d-4283-9517-b33051855a07.png,Metrics of evolved ExquisiteNetV2 models.
./dataset/abc215dc-dcc9-4b98-8fa1-8d9dba43e027.png,LLM Driven Code Block Mating
./dataset/adfedbac-161c-493f-b9e3-6610226f23c8.png,Evolved ExquisiteNetV2 models compared to State of the Art.
./dataset/f057cf54-3019-409f-824e-fd7935d52f9a.png,Example of an augmented code block.
./dataset/857a6abd-2312-463f-8a07-5e5a99ff5f7b.png,Pareto Frontier of Guided Evolution variants: Generation 9
./dataset/b9c7b809-4230-4093-9adf-ee999284dc45.png,EoT prompt template
./dataset/0eae358d-d999-454e-9ed8-9b2f4a720824.png,Guided Evolution exclusionary study.
./dataset/8810bd2e-550a-499b-bd04-aaa6098a4ebe.pdf,Illustration of self-learning LLM with intrinsic inspiration.
./dataset/029933fe-72ae-4117-b4f0-abb893b6c7fe.pdf,Illustration of self-learning LLM with extrinsic inspiration.
./dataset/b864d6af-72c7-4433-ab1f-801dd42d6192.pdf,"The illustrative space of knowledge embeddings reduced to two dimensions. It visualizes our four methods for the identification of Points in the Unknown (PiUs), later exploited in the self-learning loop. Dashed lines are the borders of the Known regions (darker green) -- hallucination score thresholds. Out of them are the Unknown regions (lighter green). White points indicate prompts related to knowledge already known to the model, while red points indicate PiUs. Different shapes depict different methods: (1) circles represent extrinsic (external) triggers, i.e., user queries or trending topics; (2) crosses denote open questions-prompts generated by the model itself within a given topic represented by a dotted line; (3) triangles represent the induced questions generated within a topic using 5W+1H; (4) stars indicate the random sampling by selecting random points in the embedding space."
./dataset/8a481d75-28d7-4044-b440-a21654e08d2f.png,Example of a figure caption.
./dataset/ea335a6d-ddc0-42dd-9fe6-a4240d86044c.pdf,3 Dimensions of Empathy and Their Subfactors
./dataset/ead6a0e0-b389-4b50-a2f0-8e07e606b66c.pdf,Scoring Accuracy of Classifiers on 15 Subfactors V2
./dataset/e98f73f7-a831-471e-b281-f86674325400.pdf,Scoring Accuracy of Classifiers on Embeddings
./dataset/67141ce4-6d32-48e2-b0fd-4b9166b55a1d.pdf,Scoring Accuracy of Different Prompt Combinations on GPT-4o-mini
./dataset/b05e4171-836c-4f0f-a5e5-18ce0e87b93a.jpg,"Our Methodology: Dataset, Models, Feature Sets, and Steps (Upper); Scoring Accuracy Achieved with Different Models and Feature Sets (Lower)"
./dataset/e2af4757-ad4a-4d23-a4e6-36fdd12f88d3.pdf,Scoring Accuracy of Classifiers on MITI Code
./dataset/00b9b755-089c-47d3-a58d-2573f78398a3.pdf,Importance of Different Features
./dataset/b1bb9416-f350-49a9-b7da-d3159cd62350.pdf,Comparison of raw results for each dimension charts for all countries.
./dataset/a739d486-1a00-4e90-b850-7a2d057ba791.pdf,"Model origin between US and China-origin models, prompted in English, Chinese, and the average of all other languages. Scores are averaged over all country results to show average alignment w.r.t. model-original and prompt language."
./dataset/32e67e17-4fe4-421a-9950-abcc54ea1731.pdf,"Comparison of ground truth and raw country results, with average ground truth and average of all LLM results."
./dataset/ff533037-18a8-4e04-a50e-41e45e27d942.pdf,Top data types by size and model count.
./dataset/e0e48d17-4df3-4038-8c65-9efd1bb894ba.pdf,Cumulative model storage by file format.
./dataset/b28283e3-171c-419a-b0d8-277dd0f13a07.pdf,Growth of base and fine-tuned models.
./dataset/f863ae7f-78e2-4877-ad18-01fedda8ec94.pdf,Impact of selected threshold on various metrics.
./dataset/1dc1e6ad-3ced-49ef-bde7-4dcc246d5d04.pdf,Expected bit distance heatmap.
./dataset/5c4c198a-f887-4a28-8f2b-c6b33a5184d8.pdf,"Distribution of data reduction ratio using different compression methods. Each violin plot illustrates the density and spread of data reduction ratios per method, overlaid with a box plot that marks the interquartile range and median."
./dataset/7c5b2000-0779-490e-9990-0a2feed39952.pdf,"Comparison between our ISM and ChatGLM when facing multi-turn dialogue data. ChatGLM applies bidirectional attention (blue frame) to prefix tokens (dialogue history) when generating answer (orange frame), our ISM applies alternate bidirectional and unidirectional attention to previous queries and answers when generating an answer. [M]:=[MASK], [S]:=[START]."
./dataset/6719bd96-6208-4a36-84d4-9932c755728f.pdf,Prompt for GPT-4. Instruction contains the task description and evaluation criteria. We provide 2 cases and corresponding human-written annotations for few-shot learning.
./dataset/ee121aa9-eae4-4f09-a5a0-7b0a9ae3adf9.pdf,"Case with longer dialogue history, includs the dialogue history, generated responses from Llama2-7b (Chatbot 1) and Llama2-7b(ISM) (Chatbot 2), and GPT-4's judgement. The two are tied."
./dataset/9afd04df-38a8-4add-b6eb-4ed79293046a.pdf,"Case with longer dialogue history, includs the dialogue history, generated responses from Llama2-7b (Chatbot 1) and Llama2-7b(ISM) (Chatbot 2), and GPT-4's judgement. Llama2-7b (ISM) wins."
./dataset/9e99c1e5-845d-440b-963e-31c947c5cce5.pdf,"Two cases are shown, each one contains the dialogue history, generated responses from Llama2-7b (Chatbot 1), Llama2-7b(ISM) (Chatbot 2), and GPT-4's judgement."
./dataset/3fcaeaac-521c-4e97-90de-2f300904a7cd.pdf,Consistency comparison between human evaluation and GPT-4 evaluation.
./dataset/7525cb8a-d2cb-4fa2-90ae-0aa2787db792.png,"A proposed workflow of incorporating LLM into content moderation. As shown in the figure, LLM can contribute in at least 6 occasions (numbers in red box): 1. distinguishing easy cases and hard cases; 2. providing information to human moderators; 3. helping human moderators generate justification for the moderation; 4. receiving feedback or appeal request from users; 5. assisting experts review by providing information; 6. disclosing results and justifications to users in an interactive way."
./dataset/aceccffa-1de1-4fbc-a6ad-d52769bbccaf.pdf,The comparative experimental results of continuous autoregressive downlink channel prediction.
./dataset/f7a38a5e-584b-41ea-95c6-423cf9ef2d19.pdf,The comparative experimental results of continuous autoregressive downlink channel prediction.
./dataset/eaa4d262-3ac3-42a9-bb7b-1096517405c3.pdf,The impact of language foundation models on the downlink channel prediction performance of Csi-LLM.
./dataset/40ad256c-dd13-45ca-af5e-e5e1af553e08.pdf,"Class distribution for various metrics, summed over all languages."
./dataset/bd0e480b-69c4-421f-b54b-613893497eae.pdf,The last row of attention matrices in early layers can locate answer-related tokens.
./dataset/f9fe5ff1-22bb-47ac-b85f-a52e7bda44f1.png,"Frequency of Survey2 task types, based on multiple choice (select all) questions asking which types of tasks participants currently use LLMs for and which tasks they would like to use LLMs for in the future."
./dataset/d1a96f78-792f-4dc7-a3ad-6fd904731268.pdf,"Precision and recall for each of 27 replicated classification tasks. Color reflects dataset, such that points sharing the same color are conducted on the same text data."
./dataset/dc58345d-1066-4db1-9abe-33eb306083d8.pdf,Change in LLM annotation performance on training data after one round of codebook updates.
./dataset/aca3a1d3-ac49-4663-9f43-268d7825bc84.pdf,"Relationship between consistency score and accuracy, TPR, and TNR."
./dataset/ea0b9209-5573-4576-972d-a1f340539fca.pdf,"Overview of Probing Dataset construction. First, we create correct character memories, which encompass the knowledge that the character should proficiently possess. Second, we inject erroneous knowledge, simulating both types of errors and preserving the modification details, which results in final queries."
./dataset/62f96e1d-02f1-41cb-ac7e-8900c270615f.pdf,"Overview of S$^2$RD. First, the model restates the character based on the profile, and this narrative serves as input for all subsequent agents. Then, it undergoes two steps of reasoning: self-recollection and self-doubt. Finally, all results are combined into the context of the last agent to detect errors."
./dataset/283f64ae-5c10-4528-8846-4af87ece662a.pdf,"The real responses of GPT-3.5-turbo-0125 while playing Isaac Newton revealed some inconsistencies. In (a), although the LLM denied that Marie Curie was a scientist from Newton's time, it still showed an undue familiarity with her, exceeding the character's knowledge boundaries. In (b), the LLM incorrectly attributed the invention of the microscope, which was created before Newton's birth, to the wrong inventor."
./dataset/54fbfd72-a22c-4959-9f10-9ac59a2b5929.pdf,The accuracy of the LLM judges based on human annotations.
./dataset/c0054529-86d2-49f1-b4fe-e2929caf84bb.png,Comparing our dataset for Documentation generation evaluation with real-world usage across languages.
./dataset/0a1ec7e1-6673-4408-a2d5-14d34cdf12db.png,A developer uses /doc to generate documentation for a function that generates Fibonacci numbers. The LLM generates the documentation for this function highlighted in diff format.
./dataset/58518ec8-dc90-4db7-b192-48b0e4406fb8.png,"A developer has typed the description of a function, which in this case should generate fibonnaci numbers. The LLM has generated the code for this function highlighted in diff format."
./dataset/2e808e42-067e-419c-99ee-38f2e540f055.png,Comparing our dataset for Bug Fixing evaluation with real-world usage across languages.
./dataset/5c405d11-f6ca-4fc4-8f3b-e159cc935efa.png,"A developer asks the model to fix an error in their fibonacci code, and the model presents the fix (spelling the word ""yield"" correctly) in diff format."
./dataset/65fb7531-35a5-4d27-8a73-bf2de0f64ba9.pdf,Model scale vs. compression ratio.
./dataset/648d5d46-cc16-48c3-b995-1a978d3c87f8.pdf,N-gram frequency count for LLM-generated synthetic data.
./dataset/2e82fb8c-5465-44e3-99a7-54dbd05e56db.pdf,LLM-generated data distribution.
./dataset/163e30a0-0841-4a77-9e6c-e58a9e87b666.pdf,General process of Neural-based Compression.
./dataset/dad9e41d-fcab-45c9-a7cc-163bfe45ad6f.pdf,Performances of domain-specific models on Math and Code tasks. Domain-specific models consistently achieve higher compression ratios within their respective domains.
./dataset/987e5d55-553a-4148-8301-ce913a7b9d78.pdf,"Compression ratio comparison between human-generated and LLM-generated text. LLMs achieve significantly higher compression ratios on LLM-generated data, with the gap widening as chunk size increases."
./dataset/4f0920b5-7502-4c58-9d13-66682a7f6c03.pdf,Trend of increasing LLM-generated data.
./dataset/8e292c76-a138-46e2-b23e-a428d49ba198.pdf,"Compression ratio comparison across different Llama models. Larger models achieve higher compression ratios, demonstrating the advantage of increased model capacity in leveraging contextual information. Instruction-tuned variants generally perform slightly worse than their base counterparts on most datasets but achieve better compression on question-answering datasets."
./dataset/aa237ae1-0175-47a6-bf0c-f6a3cf827b6f.pdf,"Compression ratio variations with increasing dataset size. Traditional methods remain stable, while neural compressors show slight improvement, but the proposed method consistently outperforms all approaches."
./dataset/74a72fe1-0557-4b5f-b371-9eb3ccffd7db.pdf,The LEA distribution for generic RAG-based CVE queries across four LLMs
./dataset/ebedec02-be60-4503-a9be-09b6771b82f5.pdf,The step-by-step of getting the hidden state progression and probability differences.
./dataset/2740e7cf-fd3c-4cec-bb6a-c6f9f1604168.pdf,The LEA distribution of Base-generated ($y'$) Responses with Stop-word Filtering and Thresholding
./dataset/65bb5573-e137-4680-bf9e-d59327370401.pdf,The LEA distribution for verified RAG-based CVE queries across four LLMs
./dataset/0da9ce00-257d-48ba-9a61-e2669394cadb.pdf,The process to derive LEA with the dependent vectors with (top) and without (bottom) retrieved context.
./dataset/13c9df68-cc02-44c6-b270-8c027c470640.pdf,Content model on LLM-assisted implementation
./dataset/eb4433a9-7b34-4504-b95a-6ea09d393007.pdf,Process model on LLM-assisted implementation
./dataset/701ac2b9-f3c8-470a-9cc0-e5d2092c159b.pdf,"Comparing three robotic grasping approaches: 1) Traditional CNN-based algorithms produce fixed poses, which lack adaptability in practical situations. 2) Multi-model LLMs output adaptable grasping strategies but lack precise numerical predictions. 3) Ours combines the best of both, predicting adaptable numerical grasping informed by reasoned strategies."
./dataset/9502dc4f-804b-413c-a849-63ac7d127a0a.pdf,Validation accuracy of our method (RT-Grasp) for two training strategies.
./dataset/354b3940-dfd9-4151-b34f-c50290929ac7.pdf,Examples of reasoning templates within the Reasoning Tuning VLM dataset.
./dataset/6704c76d-0d38-480f-b0ae-95f0118d0b24.pdf,"Reasoning and interactive refinement. Outputs from RT-Grasp include a reasoning phase (in blue) and a numerical grasp pose. The initial predicted grasp is indicated in red, while the grasp after refinement is denoted in green."
./dataset/efcb118b-548b-4455-8d03-939ac4d6883e.pdf,Illustration of two variants in ablation studies.
./dataset/a81019d2-b638-4a05-8994-06a5e5e3e828.pdf,Grasp Accuracy on household test objects.
./dataset/10b7e4e6-99f2-4ed9-b308-a9f20484bf1b.pdf,Two training strategies. 1) Pre-training: only parameters of the projection layer are trainable; 2) LoRA fine-tuning: only parameters of the projection layer and LoRA model are trainable.
./dataset/c4980f61-19dd-48a5-a073-8b6965887b8e.jpg,Household test objects for real-world grasping experiments.
./dataset/b1d82b75-bc77-40ba-a38b-18f439c27d1d.pdf,Naturally-sourced inputs.
./dataset/086ce8ee-74e6-408c-9ae8-bebfdfe3ab7d.pdf,Template-based inputs.
./dataset/8c270b6a-569f-49bd-a2de-09c52ca4d4d8.pdf,LLM-generated inputs.
./dataset/52ac248f-fbb3-4ab2-9868-48f12da36b13.pdf,LLM-generated inputs.
./dataset/e9e6d9a8-3101-4673-b0bd-47b59e8b72a6.pdf,Naturally-sourced inputs.
./dataset/68a61707-b0e9-4e53-95bf-265272f432c7.pdf,Template-based inputs.
./dataset/9ea5e217-f086-4381-a64d-81d49807ed22.pdf,LLM-generated inputs.
./dataset/ceb1f1a5-6536-428e-a8da-09edbb85117f.pdf,Naturally-sourced inputs.
./dataset/15dfa0d6-f342-4504-8369-635a69a1c5da.pdf,Template-based inputs.
./dataset/a4c85b03-5dee-4c56-b119-1f754943d233.pdf,Statistics of token alignment from LLaMA to Baichuan. Similarity scores are divided into four subsets based on alignment performances. We intend to retain the pairs highlighted in green and discard those highlighted in red.
./dataset/f758075a-33bb-4ac9-847c-7185c3372842.pdf,"Effect of number of ensemble models. The orange bars represent the performance of individual models, while the green line denotes the result of ensembling multiple models, denoted by their initials."
./dataset/a5d8cf4c-d384-4ca7-b55a-970eaefc53b4.pdf,"The rate of overlapping tokens between different LLMs vocabularies. The models are arranged in ascending order based on vocabulary size. Each cell represents the proportion of shared tokens between the horizontal and vertical models, relative to the vocabulary size of the vertical model."
./dataset/749b1617-23b8-4d35-b767-932f20bd6d0c.pdf,The average edit distance of GSM8K (orange solid line) and Flores-Zh-En (green dotted line) tasks across various top-$n$ ranges. The average edit distance indicates the output token diversity.
./dataset/0f67921b-e942-4b67-889b-29c7fd366431.png,A typical application-focused depiction of LLM agents.
./dataset/c35cc7ef-d861-4284-9fb1-52a6021259de.png,An example scenario featuring a pescetarian meal assistant LLM agent.
./dataset/31050065-73dc-46dd-9b82-0a5caf0df293.png,"We report the results of three LLMs with different numbers of new APIs in sub-figures (a), (b), and (c). The session-based accuracy of all LLMs' editing template task performance is pretty low (<4)."
./dataset/3d1cdae3-bb0f-4bf9-9943-245a04f61028.png,We illustrate the turn-base multilingual results of closed-source LLMs.
./dataset/636c4bf0-d295-4681-8eae-98704de8a526.png,"We illustrate the session-based results of closed-source LLMs in the creating new slides task, where the instructions are translated into 14 non-English languages. The bar for each language represents the LLM's accuracy in the corresponding language setting. The dotted line is the LLM's accuracy when tested in the English setting."
./dataset/95353f80-a8a1-412e-acfb-a58475a4b0a2.png,"We illustrate the turn-based results of closed-source LLMs in the creating new slides task, where the instructions are translated into 14 non-English languages. The bar for each language represents the LLM's accuracy in the corresponding language setting. The dotted line is the LLM's accuracy when tested in the English setting."
./dataset/eef584e9-843e-44a1-92ec-1ab10af610fd.png,"We illustrate the turn-based results of closed-source LLMs in the editing template task, where the instructions are translated into 14 non-English languages. The bar for each language represents the LLM's accuracy in the corresponding language setting. The dotted line is the LLM's accuracy when tested in the English setting."
./dataset/9c0336c1-2fa2-4fd4-a603-7285ab43b406.pdf,Overall Accuracy (Left) and Expert Routing Accuracy (Right) on MMLU-Expert as the size of the expert query set per expert increases.
./dataset/8c0fe371-dbe7-40b0-8d63-3df2d4d764e9.pdf,Routing expert distribution of Meta-Prompting-E (top) and ETR (down).
./dataset/d4002e3e-88bc-4655-a978-42e33d4d7572.pdf,Expert LLMs' accuracy on MMLU-Expert.
./dataset/0f5f74df-433f-4817-bccc-c53cd77490ec.pdf,A running case of extracting knowledge from GPT-4 by generating synthetic questions and answers.
./dataset/4afbc523-456a-4ebd-9ed1-8dcbe43c725e.pdf,More attacking examples - unsafe inquiry.
./dataset/301e714d-5f71-4b40-86c0-6c0263f9f892.pdf,More attacking examples - disguise.
./dataset/e5221878-a253-4976-acc2-59ee6531f694.pdf,Sub-components of each dimension and the corresponding example prompts.
./dataset/157590fe-750f-4c01-b0bc-ced4f035d879.pdf,More attacking examples - reverse induction.
./dataset/e27e597e-b09b-437d-8f3b-01f51c287c71.pdf,Example of GPT-4 assessment with 0-shot prompting and 5-shot prompting under the subcomponent of Environmental friendly (Morality).
./dataset/5be79586-b847-46a9-8817-05b7b46002ac.pdf,Propotion of each label.
./dataset/ec2dcb57-0b61-42d0-ae65-787e4e9fe7b8.pdf,Harmless rate on each subcomponent.
./dataset/17f9dec6-7e71-4b08-a3d3-83c78d1d5d85.pdf,Illustration of the proposed approach and evaluation methodology.
./dataset/bc8b7051-f3b8-44f4-a56f-fc63230ee49f.pdf,Examples of per-instance analysis.
./dataset/41447832-9be2-413f-ba52-91d5a54721f2.png,Trigger Classification
./dataset/ff8cbca7-0bcd-43af-a575-d9b2c8bbb5a2.png,Text Chunking
./dataset/fe9c28a2-b66d-4ef8-bd1a-18e8585ada94.png,Validation set micro F1 SL scores of small pre-trained MLM-based encoder and CLM-based decoder models after fine-tuning on SL tasks training data starting from particular LM checkpoint. Decoder Unmask: model pre-trained with CLM and a CM but fine-tuned without the CM. All results are averages over five runs. The shaded area represents the standard deviation.
./dataset/75d2bfde-dd06-441b-96d6-3480b62eace5.png,ATE+ATP
./dataset/2dbde1b1-b7de-4734-a689-5d68229c0c8f.png,"Layer-wise causal mask removal from decoder block groups in a decoder-only LLM. Here, the causal mask is removed from the top eight decoder blocks of the Llama2-7B model to enable bidirectionality during fine-tuning, which proves beneficial for many SL tasks."
./dataset/ccbfbd80-9a3f-4ecd-8904-834056bedc67.png,NER
./dataset/6b0dbe12-1a7d-437a-a829-e465fe5e84a6.pdf,ra
./dataset/90eda147-ce21-4566-b454-a8b0fa36945a.pdf,wikics
./dataset/a011538d-1b4d-4d3e-8478-9604f7126554.pdf,wikics
./dataset/c7aafe74-38ef-4b32-b613-fc03a956bc48.pdf,wikics
./dataset/07e547b3-07e5-4a87-8d0b-3a8b89045626.pdf,Relationship between the group accuracies sorted by confidence generated by LLMs. $k$ refers to the number of nodes selected in the groups.
./dataset/b50ba3bf-1f34-49b2-be5f-ff9d7be2b6bf.pdf,eseer
./dataset/3d4d0bfa-070e-49f8-b2d0-05644a5d004c.pdf,ra
./dataset/b41ccc61-fbba-473d-bda1-5fc2288e4b06.pdf,eseer
./dataset/87411a41-6ec9-4f05-80c2-e931658b7276.pdf,ra
./dataset/585b1a95-f58a-443f-9a3b-bbebb57c8dfd.pdf,Relationship between the group accuracies sorted by confidence generated by LLMs. $k$ refers to the number of nodes selected in the groups.
./dataset/bf3954b6-997c-4838-87bb-d40296b2edbb.pdf,ra
./dataset/13b9d141-07d7-43ee-ac9d-0624def9f4a5.pdf,ubmed
./dataset/78dd7532-323f-4443-99fc-bdbe3cf42146.pdf,ra
./dataset/9ce87015-fc64-41b8-9b55-17b232dc734d.pdf,TopK
./dataset/df780c0c-ad37-42da-ad02-929c78b00592.pdf,Zero-shot
./dataset/776c4265-b2ec-4f7c-87b7-fa82d1705a61.pdf,eseer
./dataset/12a824fe-9dff-4145-affd-e47da8dc2565.pdf,wikics
./dataset/489d8b39-086a-4b72-9b95-05eb5b9bb0ed.pdf,Hybrid
./dataset/ae1175b7-c147-4928-a810-0b9426403405.pdf,wikics
./dataset/c05d1ca4-531a-4a7a-9327-b202a3967647.pdf,eseer
./dataset/3ecddaa7-1c55-4f39-aaea-98443d36612d.pdf,ra
./dataset/7a4c7f3c-35f9-4854-9f74-55a4acd46aa7.pdf,eseer
./dataset/8692964a-5e9c-49b8-9e2d-58315597ff7a.pdf,The responses of LLMs given a gaslighting conversation history.
./dataset/f707f364-e609-4df2-8c7f-e17b123086c2.pdf,Mistral attack
./dataset/7e76a7ec-d4de-44f4-9979-ff7eafb8084d.pdf,Safety alignment on Mistral
./dataset/c00b0418-a87a-430d-bf0f-e8a5600e536e.pdf,Mistral safety
./dataset/d3ed3500-9875-4752-bd1d-6a8354955850.pdf,Attack on Vicuna
./dataset/313447be-d4f7-4cb6-9018-3d1dbd12f323.pdf,Vicuna safety
./dataset/d970e40d-8691-421b-b549-354c8c475c84.pdf,Safety alignment on LlaMa2
./dataset/cc7dbe9b-a7fc-40ac-9021-f41d3d7ac42a.pdf,Vicuna attack
./dataset/7d335921-6d61-48aa-b101-77281bd67bb6.pdf,K-means clustering of conversation backgrounds
./dataset/01a8534e-51b8-4bec-98d0-757f0f2412b3.pdf,Attack results on Mistral
./dataset/ce3795c0-1e73-4824-a5bb-33f11a3e75cc.pdf,Safety alignment on Vicuna
./dataset/9c109c9e-f02f-4a58-935f-5b7a055ce097.pdf,Attack results on LlaMa2
